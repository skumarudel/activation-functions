# 🔍 Neural Network Function Approximation App

This Streamlit app visually demonstrates how a neural network can approximate different **nonlinear functions** using various **activation functions**. It shows the power of neural networks and highlights why **nonlinear activation** is crucial in building complex models.

---

## 🚀 Features

- Select from several activation functions:
  - ReLU
  - Sigmoid
  - Tanh
  - LeakyReLU
  - ELU
  - **Linear (to illustrate its limitations)**
- Adjust:
  - Number of hidden layers
  - Number of neurons per layer
  - Number of training epochs
  - Different non-linear functions